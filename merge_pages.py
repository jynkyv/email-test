import pandas as pd
import os
import glob
from datetime import datetime

def merge_page_files():
    """åˆå¹¶æ‰€æœ‰åˆ†é¡µæ•°æ®æ–‡ä»¶"""
    
    # æŸ¥æ‰¾æ‰€æœ‰åˆ†é¡µæ•°æ®æ–‡ä»¶
    pattern = "gai-rou_companies_pages_*.csv"
    csv_files = glob.glob(pattern)
    
    if not csv_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆ†é¡µæ•°æ®æ–‡ä»¶")
        print(f"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}")
        print(f"ğŸ” æŸ¥æ‰¾æ¨¡å¼: {pattern}")
        return None
    
    # æŒ‰æ–‡ä»¶åæ’åº
    csv_files.sort()
    
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªåˆ†é¡µæ•°æ®æ–‡ä»¶:")
    for i, file in enumerate(csv_files, 1):
        file_size = os.path.getsize(file) / 1024  # KB
        print(f"   {i}. {file} ({file_size:.1f} KB)")
    
    # è¯»å–å¹¶åˆå¹¶æ‰€æœ‰æ–‡ä»¶
    all_dataframes = []
    total_rows = 0
    
    for file in csv_files:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_dataframes.append(df)
            total_rows += len(df)
            print(f"âœ… è¯»å– {file}: {len(df)} è¡Œ")
        except Exception as e:
            print(f"âŒ è¯»å– {file} å¤±è´¥: {e}")
    
    if not all_dataframes:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®æ¡†
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    
    # å»é‡ï¼ˆåŸºäºURLï¼‰
    before_dedup = len(merged_df)
    merged_df = merged_df.drop_duplicates(subset=['URL'], keep='first')
    after_dedup = len(merged_df)
    
    print(f"\nğŸ“Š åˆå¹¶ç»Ÿè®¡:")
    print(f"   åˆå¹¶å‰æ€»è¡Œæ•°: {before_dedup}")
    print(f"   å»é‡åæ€»è¡Œæ•°: {after_dedup}")
    print(f"   å»é‡æ•°é‡: {before_dedup - after_dedup}")
    
    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº
    columns_order = ['å›£ä½“å', 'ä½æ‰€', 'FAXç•ªå·', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'URL']
    merged_df = merged_df[columns_order]
    
    # ç”Ÿæˆåˆå¹¶æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"gai-rou_companies_merged_{timestamp}.csv"
    
    # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    merged_df.to_csv(output_filename, index=False, encoding="utf-8-sig")
    print(f"\nâœ… åˆå¹¶æ–‡ä»¶å·²ä¿å­˜: {output_filename}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(output_filename) / 1024:.1f} KB")
    
    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    print(f"\nğŸ“‹ åˆå¹¶åæ•°æ®é¢„è§ˆ:")
    print(merged_df.head())
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"   æ€»ä¼ä¸šæ•°: {len(merged_df)}")
    print(f"   æœ‰åœ°å€çš„ä¼ä¸š: {len(merged_df[merged_df['ä½æ‰€'] != ''])}")
    print(f"   æœ‰FAXçš„ä¼ä¸š: {len(merged_df[merged_df['FAXç•ªå·'] != ''])}")
    print(f"   æœ‰é‚®ç®±çš„ä¼ä¸š: {len(merged_df[merged_df['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] != ''])}")
    
    return output_filename

def merge_specific_files(file_patterns):
    """åˆå¹¶æŒ‡å®šæ¨¡å¼çš„æ–‡ä»¶"""
    all_files = []
    for pattern in file_patterns:
        files = glob.glob(pattern)
        all_files.extend(files)
    
    if not all_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æŒ‡å®šæ¨¡å¼çš„æ–‡ä»¶")
        return None
    
    # å»é‡å¹¶æ’åº
    all_files = sorted(list(set(all_files)))
    
    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶:")
    for file in all_files:
        print(f"   - {file}")
    
    # è¯»å–å¹¶åˆå¹¶
    all_dataframes = []
    for file in all_files:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_dataframes.append(df)
            print(f"âœ… è¯»å– {file}: {len(df)} è¡Œ")
        except Exception as e:
            print(f"âŒ è¯»å– {file} å¤±è´¥: {e}")
    
    if not all_dataframes:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
        return None
    
    # åˆå¹¶æ•°æ®
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    
    # å»é‡
    before_dedup = len(merged_df)
    merged_df = merged_df.drop_duplicates(subset=['URL'], keep='first')
    after_dedup = len(merged_df)
    
    print(f"\nğŸ“Š åˆå¹¶ç»Ÿè®¡:")
    print(f"   åˆå¹¶å‰: {before_dedup} è¡Œ")
    print(f"   å»é‡å: {after_dedup} è¡Œ")
    print(f"   å»é‡: {before_dedup - after_dedup} è¡Œ")
    
    # ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"gai-rou_companies_custom_merged_{timestamp}.csv"
    
    columns_order = ['å›£ä½“å', 'ä½æ‰€', 'FAXç•ªå·', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹', 'URL']
    merged_df = merged_df[columns_order]
    merged_df.to_csv(output_filename, index=False, encoding="utf-8-sig")
    
    print(f"âœ… åˆå¹¶æ–‡ä»¶å·²ä¿å­˜: {output_filename}")
    return output_filename

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # å¦‚æœæä¾›äº†æ–‡ä»¶æ¨¡å¼å‚æ•°
        patterns = sys.argv[1:]
        print(f"ğŸ” ä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶æ¨¡å¼: {patterns}")
        merge_specific_files(patterns)
    else:
        # é»˜è®¤åˆå¹¶æ‰€æœ‰åˆ†é¡µæ–‡ä»¶
        print("ğŸ”„ å¼€å§‹åˆå¹¶æ‰€æœ‰åˆ†é¡µæ•°æ®æ–‡ä»¶...")
        merge_page_files()